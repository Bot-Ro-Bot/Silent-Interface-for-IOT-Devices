{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import biosppy\n",
    "import scipy.signal as sig\n",
    "from scipy.stats import zscore\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft,fftfreq\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "mlp.rc(\"xtick\",labelsize=10)\n",
    "mlp.rc(\"ytick\",labelsize=10)\n",
    "mlp.rc(\"axes\",labelsize=11)\n",
    "plt.rcParams[\"figure.figsize\"] = [11,5]\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \".\"\n",
    "if os.path.basename(os.getcwd())!=\"Silent-Interface-for-IOT-Devices\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "DATA_DIR = os.path.join(MAIN_DIR,\"new dataset\")\n",
    "FIG_DIR = os.path.join(MAIN_DIR,\"figures\")\n",
    "PICKLE_DIR = os.path.join(MAIN_DIR,\"pickles\")\n",
    "os.makedirs(FIG_DIR,exist_ok=True)\n",
    "os.makedirs(PICKLE_DIR,exist_ok=True)\n",
    "\n",
    "# hardware definitions\n",
    "\"\"\"\n",
    "https://docs.openbci.com/docs/02Cyton/CytonDataFormat#:~:text=By%20default%2C%20our%20Arduino%20sketch,of%200.02235%20microVolts%20per%20count\n",
    "\"\"\"\n",
    "SAMPLING_RATE = 250 #Hz\n",
    "NUM_CHANNELS = 8 \n",
    "ADC_RESOLUTION = 24 #bits\n",
    "ADC_GAIN = 24.0\n",
    "REF_VOLTAGE = 4.5 #Volts\n",
    "SCALE_FACTOR = (REF_VOLTAGE/float((pow(2,23))-1)/ADC_GAIN)*1000000.0 #micro-volts\n",
    "\n",
    "# dataset definitions\n",
    "SPEAKER = [\"RL\",\"RN\",\"SR\",\"US\"]\n",
    "SESSION = [\"session\"+str(i) for i in range(1,9)]\n",
    "MODE = [\"mentally\",\"mouthed\"]\n",
    "SENTENCES =[\"अबको समय सुनाउ\",\"एउटा सङ्गित बजाउ\",\"आजको मौसम बताउ\",\"बत्तिको अवस्था बदल\",\"पङ्खाको स्तिथी बदल\"]\n",
    "LABELS = np.array(SENTENCES)[[3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0]]\n",
    "WORDS = [\"समय\",\"सङ्गित\",\"मौसम\",\"बत्ति\",\"पङ्खा\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files in the dataset:  155\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(DATA_DIR+\"/**/*.txt\",recursive=True)\n",
    "print(\"The files in the dataset: \",len(all_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(files,DEPLOY=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    parser function to extract utterances from .txt file and store them in a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # PERCENTILES FOR LENGTH NORMALIZATION\n",
    "    percentile_95 = 1602\n",
    "    percentile_97 = 1614\n",
    "    percentile_99 = 1648\n",
    "    percentile_100 = 1875\n",
    "    \n",
    "    \n",
    "    dataset = {\"data\":[], \"speaker\":[],\"session\":[],\"labels\":[]}\n",
    "    \n",
    "    def get_data(file):\n",
    "        \n",
    "        signal = read_data(file)\n",
    "        \n",
    "        if(DEPLOY==True):\n",
    "            dataset[\"data\"].extend(signal)\n",
    "            return\n",
    "        \n",
    "        if(len(signal)!=15):\n",
    "            return\n",
    "        \n",
    "        session = file.split(\"/\")[-2]\n",
    "        speaker = file.split(\"/\")[-3]\n",
    "        \n",
    "        dataset[\"data\"].extend(signal)\n",
    "        dataset[\"speaker\"].extend([speaker]*len(signal))\n",
    "        dataset[\"session\"].extend([session]*len(signal))\n",
    "        dataset[\"labels\"].extend(LABELS)\n",
    "        \n",
    "    \n",
    "    def read_data(file):\n",
    "        f = open(file, 'r')\n",
    "        contents = map(lambda x : x.strip(), f.readlines())\n",
    "        #the file starts with '%' and some instruction before data and removing these data \n",
    "        frames_original = list(filter(lambda x : x and x[0] != '%', contents))[1:]\n",
    "        #the data row contains channels info digital trigger and accelerometer info separated by comma\n",
    "        frames_original = list(map(lambda s : list(map( lambda ss: ss.strip(), s.split(','))), frames_original))\n",
    "        # (8 channels) + digital triggers\n",
    "        # the digital trigger is in a[16], used to indicate the utterance\n",
    "        frames = list(map(lambda a: list(map(float, a[1:9])) + [float(a[16])] , frames_original))\n",
    "        frames = np.array(frames)\n",
    "        indices = []\n",
    "        signal = []\n",
    "        for index,f in enumerate(frames[:,-1]):\n",
    "            if(bool(f) ^ bool(frames[(index+1) if ((index+1)<len(frames)) else index,-1]) ):\n",
    "                indices.append(index)\n",
    "                if len(indices)>1 and len(indices)%2==0:\n",
    "                    frame_len = indices[len(indices)-1] - indices[len(indices)-2]\n",
    "                    if(frame_len<percentile_99):\n",
    "                        pad = int(np.ceil((percentile_99 - frame_len)/2))\n",
    "                    else:\n",
    "                        pad = 0\n",
    "                    left_pad = indices[len(indices)-2] - pad\n",
    "                    right_pad = indices[len(indices)-1] + pad\n",
    "                    a_frame = (frames[left_pad:right_pad,:-1])[:percentile_99]\n",
    "                    signal.append(a_frame)\n",
    "    \n",
    "        # convert to microVolts and return\n",
    "        return np.array(signal)*SCALE_FACTOR\n",
    "        \n",
    "    for file,i in zip(files,tqdm.tqdm(range(1,len(files)+1),desc=\"PARSING DATA\")):\n",
    "        get_data(file)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PARSING DATA:  99%|█████████▉| 154/155 [01:28<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if \"data_dict.pickle\" in os.listdir(PICKLE_DIR):\n",
    "    print(\"Fetching raw data from pickle file ...\")\n",
    "    all_data = pickle.load(open(os.path.join(PICKLE_DIR,\"data_dict.pickle\"),\"rb\"))\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    all_data = parser(all_files)\n",
    "    pickle.dump(all_data,open(os.path.join(PICKLE_DIR,\"data_dict.pickle\"),\"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['data', 'speaker', 'session', 'labels'])\n",
      "[2175, 2175, 2175, 2175]\n"
     ]
    }
   ],
   "source": [
    "print(type(all_data))\n",
    "print(all_data.keys())\n",
    "DATA_LENGTH = len(all_data[\"labels\"])\n",
    "print([len(x[-1]) for x in all_data.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOISE ADDITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(data,FACTOR=0.9):\n",
    "#     noise = np.random.randn(len(data))\n",
    "# #     return FACTOR * noise\n",
    "#     new_data = data + FACTOR * noise\n",
    "#     return new_data.astype(type(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIME SHIFTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(data,SHIFT_LEN=100,SHIFT_DIR =\"RIGHT\",index=0):\n",
    "    if SHIFT_DIR != \"RIGHT\":\n",
    "        SHIFT_LEN = - SHIFT_LEN\n",
    "        index = -1\n",
    "    shifted_data = np.roll(data,SHIFT_LEN)\n",
    "    if SHIFT_LEN>0:\n",
    "        shifted_data[:SHIFT_LEN] = data[index]\n",
    "    else:\n",
    "        shifted_data[SHIFT_LEN:] = data[index]\n",
    "    return shifted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(DATA_LENGTH):\n",
    "    aug_data = []\n",
    "    for j in range(8):\n",
    "        temp_data1 = time_shift(all_data[\"data\"][i][:,j],SHIFT_DIR=\"LEFT\")\n",
    "        aug_data.append(temp_data1)\n",
    "        \n",
    "    all_data[\"data\"].extend([(np.array(aug_data)).T])\n",
    "    all_data[\"labels\"].extend([all_data[\"labels\"][i]])\n",
    "    all_data[\"speaker\"].extend([all_data[\"speaker\"][i]])\n",
    "    all_data[\"session\"].extend([all_data[\"session\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(DATA_LENGTH):\n",
    "    aug_data = []\n",
    "    for j in range(8):\n",
    "        temp_data2 = time_shift(all_data[\"data\"][i][:,j],SHIFT_DIR=\"RIGHT\")\n",
    "        aug_data.append(temp_data2)\n",
    "        \n",
    "    all_data[\"data\"].extend([(np.array(aug_data)).T])\n",
    "    all_data[\"labels\"].extend([all_data[\"labels\"][i]])\n",
    "    all_data[\"speaker\"].extend([all_data[\"speaker\"][i]])\n",
    "    all_data[\"session\"].extend([all_data[\"session\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6525, 6525, 6525, 6525]\n"
     ]
    }
   ],
   "source": [
    "print([len(x[-1]) for x in all_data.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_pipeline(data,RICKER=False):\n",
    "\n",
    "    \"\"\"\n",
    "    CORRECT DC DRIFT --> CORRECT DC BIAS --> SMOOTHING SIGNAL --> NORMALIZE DATA --> FILTER DATA \t\n",
    "    \"\"\"\n",
    "    filter_data = []\n",
    "\n",
    "    def digital_filter(data,HPF=0.5,LPF=10,H_ORDER=4,L_ORDER=4,SR=250):\n",
    "        \"\"\"\n",
    "        HPF --> NOTCH --> LPF --> RICKER CONVOLUTION\n",
    "        \"\"\"\n",
    "\n",
    "        # highpass filter\n",
    "        f_signal = biosppy.signals.tools.filter_signal(data,ftype=\"butter\",band=\"highpass\",order=H_ORDER,sampling_rate=SR,frequency=HPF)\n",
    "        # notch filter\n",
    "        b,a = sig.iirnotch(50,30,SR)\n",
    "        f_signal = sig.lfilter(b,a,f_signal[0])\n",
    "\n",
    "        # lowpass filter\n",
    "        f_signal = biosppy.signals.tools.filter_signal(f_signal,ftype=\"butter\",band=\"lowpass\",order=L_ORDER,sampling_rate=SR,frequency=LPF)\n",
    "\n",
    "        if(RICKER==True):\n",
    "            # RICKER CONVOLUTION TO REMOVE HEARTBEAT ARTIFACTS\n",
    "            ricker_width = 35 * SR // 250\n",
    "            ricker_sigma = 4.0 * SR / 250\n",
    "            ricker = sig.ricker(ricker_width,ricker_sigma)\n",
    "            # normalize ricker\n",
    "            ricker = np.array(ricker, np.float32) / np.sum(np.abs(ricker))\n",
    "            convolution = sig.convolve(f_signal[0],ricker,mode=\"same\")\n",
    "            return (f_signal[0]-2*convolution)\n",
    "\n",
    "        return f_signal[0]\n",
    "\n",
    "    def process_signal(data):\n",
    "        f_data = []\n",
    "        for i in range(8):\n",
    "            # correction of DC drift\n",
    "            c_data = data[:,i]- data[0,i]\n",
    "\n",
    "            # correct DC bias\n",
    "            c_data = c_data - np.mean(c_data)\n",
    "\n",
    "            # normalize and filter data\n",
    "            c_data = digital_filter(c_data)\n",
    "            f_data.append(c_data)\n",
    "\n",
    "        return np.array(f_data).T\n",
    "\n",
    "    for d,i in zip(data,tqdm.tqdm(range(1,len(data)+1),desc=\"PROCESSING DATA: \")):\n",
    "        temp_data = process_signal(d)\n",
    "        filter_data.extend([temp_data])\n",
    "\n",
    "    return np.array(filter_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROCESSING DATA: 100%|█████████▉| 6524/6525 [01:22<00:00, 79.16it/s]\n"
     ]
    }
   ],
   "source": [
    "if \"data_dict_filtered.pickle\" in os.listdir(PICKLE_DIR):\n",
    "    print(\"Fetching filtered data from pickle file ...\")\n",
    "    all_data_filtered = pickle.load(open(os.path.join(PICKLE_DIR,\"data_dict_filtered.pickle\"),\"rb\"))\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    all_data_filtered = all_data.copy()\n",
    "    all_data_filtered[\"data\"] = signal_pipeline(all_data[\"data\"])\n",
    "    pickle.dump(all_data_filtered,open(os.path.join(PICKLE_DIR,\"data_dict_filtered.pickle\"),\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['data', 'speaker', 'session', 'labels'])\n",
      "[6525, 6525, 6525, 6525]\n"
     ]
    }
   ],
   "source": [
    "print(type(all_data_filtered))\n",
    "print(all_data_filtered.keys())\n",
    "print([len(x[-1]) for x in all_data_filtered.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6525, 1648, 8)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(all_data_filtered[\"data\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
