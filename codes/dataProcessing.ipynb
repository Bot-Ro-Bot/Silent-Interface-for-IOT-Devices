{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the Extracted Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rimesh/Files/softwareFiles/python/ml/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import biosppy\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft,fftfreq\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "mlp.rc(\"xtick\",labelsize=10)\n",
    "mlp.rc(\"ytick\",labelsize=10)\n",
    "mlp.rc(\"axes\",labelsize=11)\n",
    "plt.rcParams[\"figure.figsize\"] = [11,5]\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make necessary definitions\n",
    "\n",
    "# directories definitions\n",
    "MAIN_DIR = \".\"\n",
    "if os.path.basename(os.getcwd())!=\"Silent-Interface-for-IOT-Devices\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "DATA_DIR = os.path.join(MAIN_DIR,\"dataset\")\n",
    "NEW_DATA_DIR = os.path.join(MAIN_DIR, \"new dataset\")\n",
    "FIG_DIR = os.path.join(MAIN_DIR,\"figures\")\n",
    "PICKLE_DIR = os.path.join(MAIN_DIR,\"pickles\")\n",
    "os.makedirs(FIG_DIR,exist_ok=True)\n",
    "os.makedirs(PICKLE_DIR,exist_ok=True)\n",
    "\n",
    "# hardware definitions\n",
    "\"\"\"\n",
    "https://docs.openbci.com/docs/02Cyton/CytonDataFormat#:~:text=By%20default%2C%20our%20Arduino%20sketch,of%200.02235%20microVolts%20per%20count\n",
    "\"\"\"\n",
    "SAMPLING_RATE = 250 #Hz\n",
    "NUM_CHANNELS = 8 \n",
    "ADC_RESOLUTION = 24 #bits\n",
    "ADC_GAIN = 24.0\n",
    "REF_VOLTAGE = 4.5 #Volts\n",
    "SCALE_FACTOR = (REF_VOLTAGE/float((pow(2,23))-1)/ADC_GAIN)*1000000.0 #micro-volts\n",
    "\n",
    "# dataset definitions\n",
    "SPEAKER = [\"RL\",\"RN\",\"SR\",\"US\"]\n",
    "SESSION = [\"session1\",\"session2\",\"session3\"]\n",
    "MODE = [\"mentally\",\"mouthed\",\"audible\"]\n",
    "SENTENCES =[\"अबको समय सुनाउ\",\"एउटा सङ्गित बजाउ\",\"आजको मौसम बताउ\",\"बत्तिको अवस्था बदल\",\"पङ्खाको स्तिथी बदल\"]\n",
    "WORDS = [\"समय\",\"सङ्गित\",\"मौसम\",\"बत्ति\",\"पङ्खा\"]\n",
    "\n",
    "SENTENCE_LABEL= np.array(SENTENCES)[[0,1,2,0,3,1,0,3,0,0,1,1,3,3,4,4,2,3,1,2,2,2,4,4,4]]\n",
    "WORD_LABEL= np.array(WORDS)[[4,0,3,1,0,1,1,0,4,0,3,2,4,4,2,1,4,1,2,2,2,0,3,3,3]]\n",
    "\n",
    "NEW_LABEL = np.array(SENTENCES)[[3, 2, 1, 4, 0, 3, 2, 1, 4, 0, 3, 2, 1, 4, 0]]\n",
    "\n",
    "LABELS = {\"word\":WORD_LABEL,\"sentence\":SENTENCE_LABEL}\n",
    "\n",
    "# a function to save plotted figures\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(FIG_DIR, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### File parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of files 104\n"
     ]
    }
   ],
   "source": [
    "listOfFiles = glob.glob(NEW_DATA_DIR+\"/**/*.txt\",recursive=True)\n",
    "# listOfFiles = glob.glob(NEW_DATA_DIR+\"/**/*.txt\",recursive=True)\n",
    "print(\"no of files\", len(listOfFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(files,FILTER=True, maxSignalLength = 0):\n",
    "    \"\"\"\n",
    "    parser function to extract utterances from .txt file and store them in a dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = {\"data\":[], \"speaker\":[], \"labels\":[], \"session\":[], \"filename\":[]}\n",
    "\n",
    "    def get_data(file):\n",
    "        session = file.split(\"/\")[-2]\n",
    "        speaker = file.split(\"/\")[-3]\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        signal = read_data(file)\n",
    "#         print(len(signal), \"file : \", filename)\n",
    "        \n",
    "        # only take files with 15 labels or max labels for utterance in a stream.         \n",
    "        if(len(signal) != len(NEW_LABEL)) and FILTER :\n",
    "            return\n",
    "        \n",
    "        dataset[\"data\"].extend(signal)\n",
    "        dataset[\"speaker\"].extend([speaker]*len(signal))\n",
    "        dataset[\"session\"].extend([session]*len(signal))\n",
    "        dataset[\"labels\"].extend(NEW_LABEL)\n",
    "        dataset[\"filename\"].extend([filename]*len(signal))\n",
    "        \n",
    "    def read_data(file):\n",
    "        f = open(file, 'r')\n",
    "        contents = map(lambda x : x.strip(), f.readlines())\n",
    "        #the file starts with '%' and some instruction before data and removing these data \n",
    "        frames_original = list(filter(lambda x : x and x[0] != '%', contents))[1:]\n",
    "        #the data row contains channels info digital trigger and accelerometer info separated by comma\n",
    "        frames_original = list(map(lambda s : list(map( lambda ss: ss.strip(), s.split(','))), frames_original))\n",
    "        # (8 channels) + digital triggers\n",
    "        # the digital trigger is in a[16], used to indicate the utterance\n",
    "        frames = list(map(lambda a: list(map(float, a[1:9])) + [float(a[16])] , frames_original))\n",
    "        frames = np.array(frames)\n",
    "        indices = []\n",
    "        signal = []\n",
    "        for index,f in enumerate(frames[:,-1]):\n",
    "            if(bool(f) ^ bool(frames[(index+1) if ((index+1)<len(frames)) else index,-1]) ):\n",
    "                indices.append(index)\n",
    "                if len(indices)>1 and len(indices)%2==0:\n",
    "                    signalTrueLength = indices[len(indices)-1] - indices[len(indices)-2]\n",
    "                    padWidth = 0\n",
    "                    if (maxSignalLength != 0) and  (signalTrueLength < maxSignalLength):\n",
    "                        padWidth = maxSignalLength - signalTrueLength\n",
    "                    \n",
    "                    signalStartIndex = indices[len(indices)-2] - int(np.floor(padWidth/2))\n",
    "                    signalEndIndex = indices[len(indices)-1] + int(np.ceil(padWidth/2))\n",
    "                    signal.append(frames[signalStartIndex : signalEndIndex, :-1])   \n",
    "        \n",
    "        # convert to microVolts and return\n",
    "        return np.array(signal)*SCALE_FACTOR\n",
    "        \n",
    "    for file,i in zip(files,tqdm.tqdm(range(1,len(files)+1),desc=\"PARSING DATA\")):\n",
    "        get_data(file)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Raw Data Imports and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PARSING DATA:  99%|█████████▉| 103/104 [04:31<00:02,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "pickleDataFile =  \"new_data_dict.pickle\" \n",
    "dataNeedsUpdate = True\n",
    "if (pickleDataFile in os.listdir(PICKLE_DIR)) and (not dataNeedsUpdate):\n",
    "    #TODO : implement MLTD here ???\n",
    "    parsedData = pickle.load(open(os.path.join(PICKLE_DIR, pickleDataFile), \"rb\"))\n",
    "else : \n",
    "    parsedData = parser(listOfFiles)\n",
    "    pickle.dump(parsedData, open(os.path.join(PICKLE_DIR, pickleDataFile), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['data', 'speaker', 'labels', 'session', 'filename'])\n",
      "[1455, 1455, 1455, 1455, 1455]\n"
     ]
    }
   ],
   "source": [
    "print(type(parsedData))\n",
    "print(parsedData.keys())\n",
    "print([len(parsedData[i]) for i in parsedData.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Dataframe Import and Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickleDataFile = 'new_data_dict_dataframe.pickle'\n",
    "df_dataNeedsUpdate = True\n",
    "if df_pickleDataFile in os.listdir(PICKLE_DIR) and not df_dataNeedsUpdate:\n",
    "    df = pd.read_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))\n",
    "else :\n",
    "    df = pd.DataFrame(parsedData)\n",
    "    df.to_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"data\"].iloc[0].shape)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding the max length of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(df[\"data\"].iloc[i]) for i in range(df.shape[0]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raw Data Import and Export :\n",
    "##### taking surrounding emg to make the total signal of equal length (to aviod paddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PARSING DATA:  99%|█████████▉| 103/104 [04:22<00:02,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "maxSignalLength = 1875 #from above\n",
    "pickleDataFile =  \"new_data_dict_equalmaxlen.pickle\" \n",
    "dataNeedsUpdate = True\n",
    "if (pickleDataFile in os.listdir(PICKLE_DIR)) and (not dataNeedsUpdate):\n",
    "    parsedData = pickle.load(open(os.path.join(PICKLE_DIR, pickleDataFile), \"rb\"))\n",
    "else : \n",
    "    parsedData = parser(listOfFiles, maxSignalLength = maxSignalLength)\n",
    "    pickle.dump(parsedData, open(os.path.join(PICKLE_DIR, pickleDataFile), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Dataframe Import and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickleDataFile = 'new_data_dict_dataframe_equalmaxlen.pickle'\n",
    "df_dataNeedsUpdate = False\n",
    "if df_pickleDataFile in os.listdir(PICKLE_DIR) and not df_dataNeedsUpdate:\n",
    "    df = pd.read_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))\n",
    "else :\n",
    "    df = pd.DataFrame(parsedData)\n",
    "    df.to_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-296.67374373,  374.01287502,  158.81399014, ...,  677.14299872,\n",
       "         -41.1475943 ,  155.25884041],\n",
       "       [-297.82383266,  373.63669341,  157.31869336, ...,  675.75457121,\n",
       "         -42.79877213,  153.90941933],\n",
       "       [-300.08651023,  372.53905687,  154.41051095, ...,  672.97981169,\n",
       "         -45.7938786 ,  150.9707652 ],\n",
       "       ...,\n",
       "       [-294.41455862,  375.58513689,  162.47856301, ...,  681.11130647,\n",
       "         -39.22712871,  160.06199892],\n",
       "       [-293.57422907,  375.25042825,  163.4587765 , ...,  681.9366621 ,\n",
       "         -38.5146996 ,  160.93879194],\n",
       "       [-295.67653724,  374.31514744,  160.72196474, ...,  679.42065021,\n",
       "         -41.2655003 ,  158.3009041 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " 1875,\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(df[\"data\"].iloc[i]) for i in range(df.shape[0]) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(index, speaker, label = \"आजको मौसम बताउ\"):\n",
    "    return df.query('speaker==\"'+speaker+'\" and labels==\"'+ label+'\"')[\"data\"].iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of RL samples in seconds : 7.50 s\n",
      "Length of US samples in seconds : 7.50 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of RL samples in seconds : %.2f s\" % (len(get_sample(1, 'RL', SENTENCES[0]))/SAMPLING_RATE))\n",
    "print(\"Length of US samples in seconds : %.2f s\" % (len(get_sample(1, 'US', SENTENCES[0]))/SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    #correct dc drift\n",
    "    \n",
    "    #correct dc bias\n",
    "    \n",
    "    #normalize data\n",
    "    \n",
    "    #filter data\n",
    "    def digital_filter(data,HPF=0.5,LPF=10,H_ORDER=4,L_ORDER=4,SR=SAMPLING_RATE):\n",
    "        # Highpass filter\n",
    "        f_signal = biosppy.signals.tools.filter_signal(data,\n",
    "                                                     ftype=\"butter\",\n",
    "                                                     band=\"highpass\",\n",
    "                                                     order=H_ORDER,\n",
    "                                                     sampling_rate=SR,\n",
    "                                                     frequency=HPF)\n",
    "\n",
    "        b,a = signal.iirnotch(50,30,SR)\n",
    "        f_signal = signal.lfilter(b,a,f_signal[0])\n",
    "        # Lowpass filter\n",
    "        f_signal = biosppy.signals.tools.filter_signal(f_signal,\n",
    "                                                     ftype=\"butter\",\n",
    "                                                     band=\"lowpass\",\n",
    "                                                     order=L_ORDER,\n",
    "                                                     sampling_rate=SR,\n",
    "                                                     frequency=LPF)\n",
    "        return f_signal[0]\n",
    "    \n",
    "    f_data = []\n",
    "    for i in range(NUM_CHANNELS):\n",
    "        c_data = data[:,i]- data[0,i]\n",
    "        c_data = c_data - np.mean(c_data)\n",
    "        c_data = digital_filter(c_data)\n",
    "        f_data.append(c_data)\n",
    "    \n",
    "    return np.array(f_data).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess dataframe import and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(tqdm.tqdm(range(len(df[\"data\"].iloc[:])),desc=\"PARSING DATA\")):\n",
    "    df[\"data\"].iloc[i] = preprocess_data(df[\"data\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "df_pickleDataFile = 'new_data_dict_dataframe_equalmaxlen_preprocess.pickle'\n",
    "df_dataNeedsUpdate = False\n",
    "if df_pickleDataFile in os.listdir(PICKLE_DIR) and not df_dataNeedsUpdate:\n",
    "    df = pd.read_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))\n",
    "else :\n",
    "    df.to_pickle(os.path.join(PICKLE_DIR, df_pickleDataFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMG(object):\n",
    "    \"\"\"\n",
    "    preprocessing and feature extraction class for EMG data\n",
    "    X = List of all instances of input data\n",
    "    x = an instance of the input data \n",
    "    Y = List of all instances of input labels\n",
    "    y = an instance of the input label\n",
    "    \n",
    "    average length of a word utterance: ( 600ms(100 wpm) + 480ms (130 wpm) + 360ms (160 wpm) ) / 3 =  480ms\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, SR,FRAME_SIZE,FRAME_SHIFT,MODE):\n",
    "        \"\"\"Set the variables \"\"\"\n",
    "        self.SR = SR\n",
    "        self.FRAME_SIZE = FRAME_SIZE\n",
    "        self.FRAME_SHIFT = FRAME_SHIFT\n",
    "        self.MODE = MODE\n",
    "        self.pickle_name = \"X_\"+MODE+\"(features).pickle\"\n",
    "    \n",
    "\n",
    "    def DNPA(self,seg):\n",
    "        \"\"\"Double Nine Point Average\"\"\"\n",
    "        w = []\n",
    "        for i in range(len(seg)):\n",
    "            a = i - 4\n",
    "            b = i + 4\n",
    "            a = a if a>=0 else 0\n",
    "            b = b if b<len(seg) else len(seg)\n",
    "            w.append(int(np.sum(seg[a:b])/9))\n",
    "\n",
    "        v = []\n",
    "        for i in range(len(seg)):\n",
    "            a = i - 4\n",
    "            b = i + 4\n",
    "            a = a if a>=0 else 0\n",
    "            b = b if b<len(seg) else len(seg)\n",
    "            v.append(int(np.sum(w[a:b])/9))\n",
    "\n",
    "        return v\n",
    "\n",
    "    \n",
    "    def ZCR(self,seg):\n",
    "        \"\"\"Zero Crossing Rate\"\"\"\n",
    "        pos = seg>0\n",
    "        npos = ~pos\n",
    "        return len(((pos[:-1] & npos[1:]) | (npos[:-1] & pos[1:])).nonzero()[0])\n",
    "\n",
    "    \n",
    "    def HFS(self,seg):\n",
    "        \"\"\"High frequency signals\"\"\"\n",
    "        return np.subtract(seg,self.DNPA(seg))\n",
    "\n",
    "    \n",
    "    def RHFS(self,seg):\n",
    "        \"\"\"Rectified High frequency signals\"\"\"\n",
    "        return abs(self.HFS(seg))\n",
    "\n",
    "    \n",
    "    def FBP(self,seg):\n",
    "        \"\"\"Frame Based Power\"\"\"\n",
    "        return np.sum(np.power(seg,2))\n",
    "\n",
    "    \n",
    "    def feature(self,seg,_type=\"time\"):\n",
    "        \"\"\" \n",
    "        \"time\": Features in time domain\n",
    "        \"freq\": Features in frequency domain\n",
    "        \"all\": Features in both domain\n",
    "        \"\"\"\n",
    "        if _type == \"time\":\n",
    "            return np.hstack((self.DNPA(seg),self.RHFS(seg),self.HFS(seg),self.ZCR(seg),self.FBP(seg)))\n",
    "        elif _type == \"freq\":\n",
    "            return \n",
    "        elif _type == \"all\":\n",
    "            return np.hstack(self.feature(seg,\"time\"),self.feature(seg,\"freq\"))\n",
    "\n",
    "    \n",
    "    def MFCC(self,seg):\n",
    "        \"\"\"Mel Frequency Cepstral Coefficients\"\"\"\n",
    "        mfcc = librosa.feature.mfcc(y=seg,sr=self.SR,n_mfcc=20)\n",
    "#         return np.mean(mfcc.T,axis=0)\n",
    "        return mfcc\n",
    "\n",
    "    \n",
    "    def STFT(self,seg):\n",
    "        \"\"\"Short Time Fourier Transform\"\"\"\n",
    "        stft = librosa.feature.chroma_stft(y=seg,sr=self.SR,n_fft=20)\n",
    "#         return np.mean(stft.T,axis=0)\n",
    "        return stft\n",
    "\n",
    "    \n",
    "    def segment(self,x):\n",
    "        \"\"\"Segmenting the data into frames and sliding them according to the frame shift\"\"\"\n",
    "        f = []\n",
    "        for channel in range(NUM_CHANNELS):\n",
    "            for i in range(x.shape[0]):\n",
    "                a = i*self.FRAME_SHIFT\n",
    "                b = a + self.FRAME_SIZE\n",
    "                if(b > x.shape[0]):\n",
    "                    break\n",
    "#                 seg = x[channel][a:b]\n",
    "                seg = x[a:b, channel]\n",
    "                f.extend(self.feature(seg))\n",
    "        return f\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        \"\"\"Extract Features and return the zero padded list of features\"\"\"\n",
    "        if(self.pickle_name in os.listdir() ):\n",
    "            print(\"Fetching Pickle file\")\n",
    "            temp_X = pickle.load(open(self.pickle_name,\"rb\"))\n",
    "        else:\n",
    "            temp_X = []\n",
    "            for x,count in zip(X, tqdm.tqdm(range(len(X)),ncols=100,desc=\"Extracting Features(\"+self.MODE+\")\" ) ):\n",
    "                temp_X.append(self.segment(x))\n",
    "\n",
    "            # save all extracted features to a pickle file\n",
    "            print(\"Saving features as: \",self.pickle_name)\n",
    "            pickle.dump(temp_X,open(self.pickle_name,\"wb\"))\n",
    "        temp_X = np.array(temp_X)\n",
    "        print(len(temp_X))\n",
    "        print(len(Y))\n",
    "        print(temp_X.shape)\n",
    "        return self.reduce_dimension(temp_X),self.encode_labels(Y)\n",
    "\n",
    "    \n",
    "    def fit_transform(self,X,Y):\n",
    "        return self.fit(X,Y)\n",
    "    \n",
    "    def getFeature(self, X):\n",
    "#         print(X.shape)\n",
    "        temp_X = []\n",
    "        for x,count in zip(X, tqdm.tqdm(range(len(X)),ncols=100,desc=\"Extracting Features(\"+self.MODE+\")\" ) ):\n",
    "            temp_X.append(self.segment(x))\n",
    "        temp_X = np.array(temp_X)\n",
    "        print(len(temp_X))\n",
    "#         print(len(Y))\n",
    "        print(temp_X.shape)\n",
    "        return temp_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features(time):   0%|                                | 3/1455 [04:22<35:20:28, 87.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cffc00f3cf09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEMG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# XXX,YYY = features.fit_transform()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36mgetFeature\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mtemp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Extracting Features(\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODE\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\")\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mtemp_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mtemp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36msegment\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m#                 seg = x[channel][a:b]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36mfeature\u001b[0;34m(self, seg, _type)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNPA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRHFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFBP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0m_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36mRHFS\u001b[0;34m(self, seg)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mRHFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m\"\"\"Rectified High frequency signals\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36mHFS\u001b[0;34m(self, seg)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mHFS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;34m\"\"\"High frequency signals\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNPA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-6cea0d689583>\u001b[0m in \u001b[0;36mDNPA\u001b[0;34m(self, seg)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = EMG(SAMPLING_RATE,16,1,\"time\")\n",
    "# XXX,YYY = features.fit_transform()\n",
    "aa = features.getFeature(df[\"data\"].iloc[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"data\"].iloc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1875, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = df[\"data\"].iloc[:]\n",
    "print(len(A))\n",
    "_a = A[0]\n",
    "_a.shape\n",
    "# print(len(_a.sja))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('speaker==\"RL\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
